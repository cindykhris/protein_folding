{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Jupyter Notebook is designed to process and analyze protein embeddings generated by a preceding script ( protein_folding/esm2_model_embeddings/extract_embeddings_esm2.py). The primary objective is to dynamically locate the output directory containing the .npy embedding files, read the files, and extract key dimensional information about the embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting embeddings in /pollard/data/projects/cpino/protein_folding/esm2_model_embeddings/examples/output_embeddings...\n",
      "File: UNIPROT:Q30PL1_embedding.npy\n",
      "  Dimensions: (624, 1280)\n",
      "  Number of Layers: 624\n",
      "  Features per Layer: 1280\n",
      "File: UNIPROT:Q5FN17_embedding.npy\n",
      "  Dimensions: (837, 1280)\n",
      "  Number of Layers: 837\n",
      "  Features per Layer: 1280\n",
      "File: UNIPROT:O66780_embedding.npy\n",
      "  Dimensions: (513, 1280)\n",
      "  Number of Layers: 513\n",
      "  Features per Layer: 1280\n",
      "File: UNIPROT:A5ULU4_embedding.npy\n",
      "  Dimensions: (1203, 1280)\n",
      "  Number of Layers: 1203\n",
      "  Features per Layer: 1280\n",
      "File: UNIPROT:P36655_embedding.npy\n",
      "  Dimensions: (1701, 1280)\n",
      "  Number of Layers: 1701\n",
      "  Features per Layer: 1280\n",
      "Inspection completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Function to iterate through embeddings and display dimensions\n",
    "def inspect_embeddings(relative_path):\n",
    "    # Get the absolute path based on the relative path\n",
    "    base_path = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "    output_dir = os.path.join(base_path, relative_path)\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Error: Directory '{output_dir}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    print(f\"Inspecting embeddings in {output_dir}...\")\n",
    "    for file_name in os.listdir(output_dir):\n",
    "        if file_name.endswith(\"_embedding.npy\"):\n",
    "            file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "            # Load the embedding file\n",
    "            embedding = np.load(file_path)\n",
    "\n",
    "            # Get the dimensions of the embedding\n",
    "            dims = embedding.shape\n",
    "\n",
    "            # Print details\n",
    "            print(f\"File: {file_name}\")\n",
    "            print(f\"  Dimensions: {dims}\")\n",
    "\n",
    "            # If it's a concatenated embedding (multiple layers), further inspect each layer\n",
    "            if len(dims) == 2:  # Assuming 2D array: (tokens, features) or (layers x features)\n",
    "                num_layers, num_features = dims\n",
    "                print(f\"  Number of Layers: {num_layers}\")\n",
    "                print(f\"  Features per Layer: {num_features}\")\n",
    "            elif len(dims) == 3:  # Assuming 3D array: (layers, tokens, features)\n",
    "                num_layers, num_tokens, num_features = dims\n",
    "                print(f\"  Number of Layers: {num_layers}\")\n",
    "                print(f\"  Tokens per Layer: {num_tokens}\")\n",
    "                print(f\"  Features per Token: {num_features}\")\n",
    "\n",
    "    print(\"Inspection completed.\")\n",
    "\n",
    "# Example usage\n",
    "relative_path = \"esm2_model_embeddings/examples/output_embeddings\"  # Provide the path relative to the current working directory\n",
    "inspect_embeddings(relative_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example for visualizing a single file\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "relative_path = \"esm2_model_embeddings/examples/output_embeddings\"\n",
    "\n",
    "\n",
    "file_path = os.path.join(base_path, relative_path, \"UNIPROT:Q30PL1_embedding.npy\")\n",
    "embedding = np.load(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Reduce dimensions for visualization\n",
    "reduced_embedding = TSNE(n_components=2, random_state=42).fit_transform(embedding)\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(reduced_embedding[:, 0], reduced_embedding[:, 1], alpha=0.7)\n",
    "plt.title(\"t-SNE Visualization of Token Embeddings (UNIPROT:Q30PL1)\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
